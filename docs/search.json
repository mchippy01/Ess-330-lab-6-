[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESS 330 lab 8",
    "section": "",
    "text": "Libraries\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(ggplot2)\nlibrary(rsample)\n\nLoad data\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n \ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\nClean data\n\nvisdat::vis_dat(camels)\n\n\n\n\n\n\n\nskimr::skim(camels)\n\n\nData summary\n\n\nName\ncamels\n\n\nNumber of rows\n671\n\n\nNumber of columns\n58\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n52\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngauge_id\n0\n1.00\n8\n8\n0\n671\n0\n\n\nhigh_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\nlow_prec_timing\n0\n1.00\n3\n3\n0\n4\n0\n\n\ngeol_1st_class\n0\n1.00\n12\n31\n0\n12\n0\n\n\ngeol_2nd_class\n138\n0.79\n12\n31\n0\n13\n0\n\n\ndom_land_cover\n0\n1.00\n12\n38\n0\n12\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\np_mean\n0\n1.00\n3.26\n1.41\n0.64\n2.37\n3.23\n3.78\n8.94\n▃▇▂▁▁\n\n\npet_mean\n0\n1.00\n2.79\n0.55\n1.90\n2.34\n2.69\n3.15\n4.74\n▇▇▅▂▁\n\n\np_seasonality\n0\n1.00\n-0.04\n0.53\n-1.44\n-0.26\n0.08\n0.22\n0.92\n▁▂▃▇▂\n\n\nfrac_snow\n0\n1.00\n0.18\n0.20\n0.00\n0.04\n0.10\n0.22\n0.91\n▇▂▁▁▁\n\n\naridity\n0\n1.00\n1.06\n0.62\n0.22\n0.70\n0.86\n1.27\n5.21\n▇▂▁▁▁\n\n\nhigh_prec_freq\n0\n1.00\n20.93\n4.55\n7.90\n18.50\n22.00\n24.23\n32.70\n▂▃▇▇▁\n\n\nhigh_prec_dur\n0\n1.00\n1.35\n0.19\n1.08\n1.21\n1.28\n1.44\n2.09\n▇▅▂▁▁\n\n\nlow_prec_freq\n0\n1.00\n254.65\n35.12\n169.90\n232.70\n255.85\n278.92\n348.70\n▂▅▇▅▁\n\n\nlow_prec_dur\n0\n1.00\n5.95\n3.20\n2.79\n4.24\n4.95\n6.70\n36.51\n▇▁▁▁▁\n\n\nglim_1st_class_frac\n0\n1.00\n0.79\n0.20\n0.30\n0.61\n0.83\n1.00\n1.00\n▁▃▃▃▇\n\n\nglim_2nd_class_frac\n0\n1.00\n0.16\n0.14\n0.00\n0.00\n0.14\n0.27\n0.49\n▇▃▃▂▁\n\n\ncarbonate_rocks_frac\n0\n1.00\n0.12\n0.26\n0.00\n0.00\n0.00\n0.04\n1.00\n▇▁▁▁▁\n\n\ngeol_porostiy\n3\n1.00\n0.13\n0.07\n0.01\n0.07\n0.13\n0.19\n0.28\n▇▆▇▇▂\n\n\ngeol_permeability\n0\n1.00\n-13.89\n1.18\n-16.50\n-14.77\n-13.96\n-13.00\n-10.90\n▂▅▇▅▂\n\n\nsoil_depth_pelletier\n0\n1.00\n10.87\n16.24\n0.27\n1.00\n1.23\n12.89\n50.00\n▇▁▁▁▁\n\n\nsoil_depth_statsgo\n0\n1.00\n1.29\n0.27\n0.40\n1.11\n1.46\n1.50\n1.50\n▁▁▂▂▇\n\n\nsoil_porosity\n0\n1.00\n0.44\n0.02\n0.37\n0.43\n0.44\n0.46\n0.68\n▃▇▁▁▁\n\n\nsoil_conductivity\n0\n1.00\n1.74\n1.52\n0.45\n0.93\n1.35\n1.93\n13.96\n▇▁▁▁▁\n\n\nmax_water_content\n0\n1.00\n0.53\n0.15\n0.09\n0.43\n0.56\n0.64\n1.05\n▁▅▇▃▁\n\n\nsand_frac\n0\n1.00\n36.47\n15.63\n8.18\n25.44\n35.27\n44.46\n91.98\n▅▇▅▁▁\n\n\nsilt_frac\n0\n1.00\n33.86\n13.25\n2.99\n23.95\n34.06\n43.64\n67.77\n▂▆▇▆▁\n\n\nclay_frac\n0\n1.00\n19.89\n9.32\n1.85\n14.00\n18.66\n25.42\n50.35\n▃▇▅▂▁\n\n\nwater_frac\n0\n1.00\n0.10\n0.94\n0.00\n0.00\n0.00\n0.00\n19.35\n▇▁▁▁▁\n\n\norganic_frac\n0\n1.00\n0.59\n3.84\n0.00\n0.00\n0.00\n0.00\n57.86\n▇▁▁▁▁\n\n\nother_frac\n0\n1.00\n9.82\n16.83\n0.00\n0.00\n1.31\n11.74\n99.38\n▇▁▁▁▁\n\n\ngauge_lat\n0\n1.00\n39.24\n5.21\n27.05\n35.70\n39.25\n43.21\n48.82\n▂▃▇▆▅\n\n\ngauge_lon\n0\n1.00\n-95.79\n16.21\n-124.39\n-110.41\n-92.78\n-81.77\n-67.94\n▆▃▇▇▅\n\n\nelev_mean\n0\n1.00\n759.42\n786.00\n10.21\n249.67\n462.72\n928.88\n3571.18\n▇▂▁▁▁\n\n\nslope_mean\n0\n1.00\n46.20\n47.12\n0.82\n7.43\n28.80\n73.17\n255.69\n▇▂▂▁▁\n\n\narea_gages2\n0\n1.00\n792.62\n1701.95\n4.03\n122.28\n329.68\n794.30\n25791.04\n▇▁▁▁▁\n\n\narea_geospa_fabric\n0\n1.00\n808.08\n1709.85\n4.10\n127.98\n340.70\n804.50\n25817.78\n▇▁▁▁▁\n\n\nfrac_forest\n0\n1.00\n0.64\n0.37\n0.00\n0.28\n0.81\n0.97\n1.00\n▃▁▁▂▇\n\n\nlai_max\n0\n1.00\n3.22\n1.52\n0.37\n1.81\n3.37\n4.70\n5.58\n▅▆▃▅▇\n\n\nlai_diff\n0\n1.00\n2.45\n1.33\n0.15\n1.20\n2.34\n3.76\n4.83\n▇▇▇▆▇\n\n\ngvf_max\n0\n1.00\n0.72\n0.17\n0.18\n0.61\n0.78\n0.86\n0.92\n▁▁▂▃▇\n\n\ngvf_diff\n0\n1.00\n0.32\n0.15\n0.03\n0.19\n0.32\n0.46\n0.65\n▃▇▅▇▁\n\n\ndom_land_cover_frac\n0\n1.00\n0.81\n0.18\n0.31\n0.65\n0.86\n1.00\n1.00\n▁▂▃▃▇\n\n\nroot_depth_50\n24\n0.96\n0.18\n0.03\n0.12\n0.17\n0.18\n0.19\n0.25\n▃▃▇▂▂\n\n\nroot_depth_99\n24\n0.96\n1.83\n0.30\n1.50\n1.52\n1.80\n2.00\n3.10\n▇▃▂▁▁\n\n\nq_mean\n1\n1.00\n1.49\n1.54\n0.00\n0.63\n1.13\n1.75\n9.69\n▇▁▁▁▁\n\n\nrunoff_ratio\n1\n1.00\n0.39\n0.23\n0.00\n0.24\n0.35\n0.51\n1.36\n▆▇▂▁▁\n\n\nslope_fdc\n1\n1.00\n1.24\n0.51\n0.00\n0.90\n1.28\n1.63\n2.50\n▂▅▇▇▁\n\n\nbaseflow_index\n0\n1.00\n0.49\n0.16\n0.01\n0.40\n0.50\n0.60\n0.98\n▁▃▇▅▁\n\n\nstream_elas\n1\n1.00\n1.83\n0.78\n-0.64\n1.32\n1.70\n2.23\n6.24\n▁▇▃▁▁\n\n\nq5\n1\n1.00\n0.17\n0.27\n0.00\n0.01\n0.08\n0.22\n2.42\n▇▁▁▁▁\n\n\nq95\n1\n1.00\n5.06\n4.94\n0.00\n2.07\n3.77\n6.29\n31.82\n▇▂▁▁▁\n\n\nhigh_q_freq\n1\n1.00\n25.74\n29.07\n0.00\n6.41\n15.10\n35.79\n172.80\n▇▂▁▁▁\n\n\nhigh_q_dur\n1\n1.00\n6.91\n10.07\n0.00\n1.82\n2.85\n7.55\n92.56\n▇▁▁▁▁\n\n\nlow_q_freq\n1\n1.00\n107.62\n82.24\n0.00\n37.44\n96.00\n162.14\n356.80\n▇▆▅▂▁\n\n\nlow_q_dur\n1\n1.00\n22.28\n21.66\n0.00\n10.00\n15.52\n26.91\n209.88\n▇▁▁▁▁\n\n\nzero_q_freq\n1\n1.00\n0.03\n0.11\n0.00\n0.00\n0.00\n0.00\n0.97\n▇▁▁▁▁\n\n\nhfd_mean\n1\n1.00\n182.52\n33.53\n112.25\n160.16\n173.77\n204.05\n287.75\n▂▇▃▂▁\n\n\n\n\ncamels &lt;- camels %&gt;%\n  drop_na()\n\nSplit data\n\nset.seed(123)\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n \n#Build resamples \ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\nFeature Engineering\nDefine recipe\n\nrec2 &lt;- recipe(logQmean ~ p_mean + slope_mean  , data = camels_train) %&gt;%\n  step_log(all_predictors())%&gt;%\n  step_interact(terms = ~ p_mean:slope_mean) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())      \n\n#Bake Data\nbaked_data2 &lt;- prep(rec2, camels_train) %&gt;%\n  bake(new_data = NULL)\n\nDefine models\n\nxgb_model2 &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nrf_model2 &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nmlp_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nDefine workflows\n\n# Random forest workflow\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2)\n\n# XGBoost workflow\nxgb_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(xgb_model2)\n\n# Bagged MLP Neural Net\nmlp_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(mlp_model) %&gt;%\n  fit(data = camels_train)\n\nTest models\n\nmy_metrics &lt;- metric_set(rmse, rsq, mae)\n\nwf_set &lt;- workflow_set(\n  preproc = list(my_recipe = rec2),\n  models = list(\n    xgboost = xgb_model2,\n    random_forest = rf_model2,\n    Bagged_Mlp = mlp_model\n  )\n)\nwf_results &lt;- wf_set %&gt;%\n  workflow_map(\n    \"fit_resamples\",\n    resamples = camels_cv,\n    metrics = my_metrics,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nautoplot(wf_results)\n\n\n\n\n\n\n\n\nFor modeling this data, I would chose the Bagged MLP model as it preforms the best. It has the lowest RMSE and MAE, which indicates better accuracy. It also has the highest R^2 which indicated better correlations.\n\n\nTune model\nDefine tunable model\n\n#MLP\nmlp_tune_model &lt;- bag_mlp(\n  hidden_units = tune(), #controls model complexity \n  penalty = tune() #prevents overfitting         \n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nCreate workflow\n\nmlp_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(mlp_tune_model)\n\nCheck tuneable values/ ranges\n\ndials &lt;- extract_parameter_set_dials(mlp_workflow)\ndials$object\n\n[[1]]\n# Hidden Units (quantitative)\nRange: [1, 10]\n\n[[2]]\nAmount of Regularization (quantitative)\nTransformer: log-10 [1e-100, Inf]\nRange (transformed scale): [-10, 0]\n\n\nDefine the search grid\n\nmy.grid &lt;- grid_latin_hypercube(\n  hidden_units(),\n  penalty(),\n  size = 25\n)\n\nWarning: `grid_latin_hypercube()` was deprecated in dials 1.3.0.\nℹ Please use `grid_space_filling()` instead.\n\nprint(my.grid)\n\n# A tibble: 25 × 2\n   hidden_units       penalty\n          &lt;int&gt;         &lt;dbl&gt;\n 1            4 0.000000367  \n 2            7 0.0000000315 \n 3            7 0.0406       \n 4            4 0.00000000329\n 5            3 0.00758      \n 6            5 0.0000253    \n 7            9 0.00115      \n 8            6 0.000000532  \n 9            3 0.338        \n10            9 0.00000862   \n# ℹ 15 more rows\n\n\n\n\nTune the model\n\nmodel_params &lt;- tune_grid(\n  mlp_workflow,          \n  resamples = camels_cv,     \n  grid = my.grid,        \n  metrics = my_metrics, \n  control = control_grid(save_pred = TRUE)\n)\n\nVisualize the results of tuning\n\nautoplot(model_params)\n\n\n\n\n\n\n\n\nBased on the results, the best models had around 4 to 7 hidden units and a moderate penalty value (between -5 and -2 on the log scale), which is to be expected. Models with too few or too many hidden units didn’t perform as well, and the same was true for penalties that were too small or too large. The best combinations (models with values within the parameters described above) gave me the lowest prediction error (MAE and RMSE) and the highest R², meaning they made more accurate predictions and explained more of the variation in the data. This shows that tuning both parameters helped me find a strong model that balances learning the data well without overfitting.\nCheck model skill\n\nmetrics_tbl &lt;- collect_metrics(model_params)\nprint(metrics_tbl)\n\n# A tibble: 75 × 8\n   hidden_units       penalty .metric .estimator  mean     n std_err .config    \n          &lt;int&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1            4 0.000000367   mae     standard   0.284    10  0.0182 Preprocess…\n 2            4 0.000000367   rmse    standard   0.411    10  0.0333 Preprocess…\n 3            4 0.000000367   rsq     standard   0.890    10  0.0142 Preprocess…\n 4            7 0.0000000315  mae     standard   0.290    10  0.0182 Preprocess…\n 5            7 0.0000000315  rmse    standard   0.419    10  0.0327 Preprocess…\n 6            7 0.0000000315  rsq     standard   0.883    10  0.0147 Preprocess…\n 7            7 0.0406        mae     standard   0.295    10  0.0185 Preprocess…\n 8            7 0.0406        rmse    standard   0.420    10  0.0306 Preprocess…\n 9            7 0.0406        rsq     standard   0.886    10  0.0125 Preprocess…\n10            4 0.00000000329 mae     standard   0.284    10  0.0167 Preprocess…\n# ℹ 65 more rows\n\n\n\nmetrics_tbl &lt;- collect_metrics(model_params)\nprint(metrics_tbl)\n\n# A tibble: 75 × 8\n   hidden_units       penalty .metric .estimator  mean     n std_err .config    \n          &lt;int&gt;         &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1            4 0.000000367   mae     standard   0.284    10  0.0182 Preprocess…\n 2            4 0.000000367   rmse    standard   0.411    10  0.0333 Preprocess…\n 3            4 0.000000367   rsq     standard   0.890    10  0.0142 Preprocess…\n 4            7 0.0000000315  mae     standard   0.290    10  0.0182 Preprocess…\n 5            7 0.0000000315  rmse    standard   0.419    10  0.0327 Preprocess…\n 6            7 0.0000000315  rsq     standard   0.883    10  0.0147 Preprocess…\n 7            7 0.0406        mae     standard   0.295    10  0.0185 Preprocess…\n 8            7 0.0406        rmse    standard   0.420    10  0.0306 Preprocess…\n 9            7 0.0406        rsq     standard   0.886    10  0.0125 Preprocess…\n10            4 0.00000000329 mae     standard   0.284    10  0.0167 Preprocess…\n# ℹ 65 more rows\n\n\n\n\n\ncollect_metrics(model_params) %&gt;%\n  filter(.metric == \"mae\") %&gt;%\n  arrange(mean)\n\n# A tibble: 25 × 8\n   hidden_units  penalty .metric .estimator  mean     n std_err .config         \n          &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;           \n 1            4 3.29e- 9 mae     standard   0.284    10  0.0167 Preprocessor1_M…\n 2            6 5.32e- 7 mae     standard   0.284    10  0.0187 Preprocessor1_M…\n 3            4 3.67e- 7 mae     standard   0.284    10  0.0182 Preprocessor1_M…\n 4            3 5.16e- 5 mae     standard   0.285    10  0.0185 Preprocessor1_M…\n 5            2 1.89e-10 mae     standard   0.285    10  0.0168 Preprocessor1_M…\n 6            5 1.79e- 8 mae     standard   0.285    10  0.0194 Preprocessor1_M…\n 7            3 7.58e- 3 mae     standard   0.286    10  0.0176 Preprocessor1_M…\n 8            4 2.92e-10 mae     standard   0.286    10  0.0195 Preprocessor1_M…\n 9            5 2.53e- 5 mae     standard   0.287    10  0.0203 Preprocessor1_M…\n10            9 1.15e- 3 mae     standard   0.288    10  0.0181 Preprocessor1_M…\n# ℹ 15 more rows\n\nshow_best(model_params, metric = \"mae\", n = 5)\n\n# A tibble: 5 × 8\n  hidden_units  penalty .metric .estimator  mean     n std_err .config          \n         &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;            \n1            4 3.29e- 9 mae     standard   0.284    10  0.0167 Preprocessor1_Mo…\n2            6 5.32e- 7 mae     standard   0.284    10  0.0187 Preprocessor1_Mo…\n3            4 3.67e- 7 mae     standard   0.284    10  0.0182 Preprocessor1_Mo…\n4            3 5.16e- 5 mae     standard   0.285    10  0.0185 Preprocessor1_Mo…\n5            2 1.89e-10 mae     standard   0.285    10  0.0168 Preprocessor1_Mo…\n\n\nThe best model has 10 hidden units and a penalty value of ~0.0068.\nThis configuration produces the lowest average MAE, meaning it makes the smallest absolute errors across all folds.\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\nMy computer is running really slow and some code isn’t running or showing the green arrow so that’s why there’s some duplicate ode. It wont even let me delete the old stuff.\n\nhp_best &lt;- select_best(model_params, metric = \"mae\")\n\n\n\nFinalize your model\n\nfinal_mlp_workflow &lt;- finalize_workflow(\n  mlp_workflow,\n  hp_best\n)\n\nFinal Model Verification\n\nfinal_mlp_last &lt;- last_fit(\n  final_mlp_workflow,   \n  split = camels_split)\n\ncollect_metrics(final_mlp_last)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       0.606 Preprocessor1_Model1\n2 rsq     standard       0.810 Preprocessor1_Model1\n\nfinal_fit_full &lt;- fit\n\nfinal_preds &lt;- collect_predictions(final_mlp_last)\n\nfinal_fit_full &lt;- fit(final_mlp_workflow, data = camels)\n\n\nnames(final_preds)\n\n[1] \".pred\"    \"id\"       \".row\"     \"logQmean\" \".config\" \n\n\nPlot predicted vs. actual\n\nggplot(final_preds, aes(x = .pred, y = logQmean)) +\n  geom_point(color = \"steelblue\", alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"darkred\") +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"black\") +\n  labs(\n    title = \"Predicted vs Actual Values\",\n    x = \"Predicted\",\n    y = \"Actual\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nBuilding a map\n\npredictions_all &lt;- augment(final_fit_full, new_data = camels)\n\npredictions_all &lt;- predictions_all %&gt;%\n  mutate(residual = (logQmean - .pred)^2) \n\npred_map &lt;- ggplot(predictions_all, aes(x = gauge_lon, y = gauge_lat, color = .pred)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(name = \"Predicted\") +\n  labs(title = \"Predicted logQmean\") +\n  coord_fixed() +\n  theme_minimal()\n\nresid_map &lt;- ggplot(predictions_all, aes(x = gauge_lon, y = gauge_lat, color = residual)) +\n  geom_point(size = 2) +\n  scale_color_viridis_c(name = \"Residual (squared)\") +\n  labs(title = \"Squared Residuals\") +\n  coord_fixed() +\n  theme_minimal()\nlibrary(patchwork)\n\npred_map + resid_map"
  },
  {
    "objectID": "lab6.html",
    "href": "lab6.html",
    "title": "ESS 330 lab 6",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.7     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.2\n✔ recipes      1.1.0     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(powerjoin)\nlibrary(glue)\nlibrary(vip)\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\nlibrary(baguette)\nlibrary(ggplot2)\n\n\nroot  &lt;- 'https://gdex.ucar.edu/dataset/camels/file'\ndownload.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', \n              'data/camels_attributes_v2.0.pdf')\n\n\ntypes &lt;- c(\"clim\", \"geol\", \"soil\", \"topo\", \"vege\", \"hydro\")\n# Where the files live online ...\nremote_files  &lt;- glue('{root}/camels_{types}.txt')\n# where we want to download the data ...\nlocal_files   &lt;- glue('data/camels_{types}.txt')\nwalk2(remote_files, local_files, download.file, quiet = TRUE)\n# Read and merge data\ncamels &lt;- map(local_files, read_delim, show_col_types = FALSE) \n\n\ncamels &lt;- power_full_join(camels ,by = 'gauge_id')\n\n\nggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = q_mean)) +\n  scale_color_gradient(low = \"pink\", high = \"dodgerblue\") +\n  ggthemes::theme_map()\n\n\n\n\n\n\n\n\n\nQuestion 1\nzero_q_freq represents frequency of days with Q = 0 mm/day (%), where Q= discharge (mm/day).\nDemo–&gt;\n\ncamels |&gt; \n  select(aridity, p_mean, q_mean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           aridity     p_mean     q_mean\naridity  1.0000000 -0.7550090 -0.5817771\np_mean  -0.7550090  1.0000000  0.8865757\nq_mean  -0.5817771  0.8865757  1.0000000\n\n\n\n# Create a scatter plot of aridity vs rainfall\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  # Add points colored by mean flow\n  geom_point(aes(color = q_mean)) +\n  # Add a linear regression line\n  geom_smooth(method = \"lm\", color = \"red\", linetype = 2) +\n  # Apply the viridis color scale\n  scale_color_viridis_c() +\n  # Add a title, axis labels, and theme (w/ legend on the bottom)\n  theme_linedraw() + \n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  scale_color_viridis_c() +\n  # Apply log transformations to the x and y axes\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\") + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(camels, aes(x = aridity, y = p_mean)) +\n  geom_point(aes(color = q_mean)) +\n  geom_smooth(method = \"lm\") +\n  # Apply a log transformation to the color scale\n  scale_color_viridis_c(trans = \"log\") +\n  scale_x_log10() + \n  scale_y_log10() +\n  theme_linedraw() +\n  theme(legend.position = \"bottom\",\n        # Expand the legend width ...\n        legend.key.width = unit(2.5, \"cm\"),\n        legend.key.height = unit(.5, \"cm\")) + \n  labs(title = \"Aridity vs Rainfall vs Runnoff\", \n       x = \"Aridity\", \n       y = \"Rainfall\",\n       color = \"Mean Flow\") \n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nset.seed(123)\n# Bad form to perform simple transformations on the outcome variable within a \n# recipe. So, we'll do it here.\ncamels &lt;- camels |&gt; \n  mutate(logQmean = log(q_mean))\n\n# Generate the split\ncamels_split &lt;- initial_split(camels, prop = 0.8)\ncamels_train &lt;- training(camels_split)\ncamels_test  &lt;- testing(camels_split)\n\ncamels_cv &lt;- vfold_cv(camels_train, v = 10)\n\n\n# Create a recipe to preprocess the data\nrec &lt;-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %&gt;%\n  # Log transform the predictor variables (aridity and p_mean)\n  step_log(all_predictors()) %&gt;%\n  # Add an interaction term between aridity and p_mean\n  step_interact(terms = ~ aridity:p_mean) |&gt; \n  # Drop any rows with missing values in the pred\n  step_naomit(all_predictors(), all_outcomes())\n# Prepare the data\nbaked_data &lt;- prep(rec, camels_train) |&gt; \n  bake(new_data = NULL)\n\n# Interaction with lm\n#  Base lm sets interaction terms with the * symbol\nlm_base &lt;- lm(logQmean ~ aridity * p_mean, data = baked_data)\nsummary(lm_base)\n\n\nCall:\nlm(formula = logQmean ~ aridity * p_mean, data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity        -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean          1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity:p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\n# Sanity Interaction term from recipe ... these should be equal!!\nsummary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))\n\n\nCall:\nlm(formula = logQmean ~ aridity + p_mean + aridity_x_p_mean, \n    data = baked_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.91162 -0.21601 -0.00716  0.21230  2.85706 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -1.77586    0.16365 -10.852  &lt; 2e-16 ***\naridity          -0.88397    0.16145  -5.475 6.75e-08 ***\np_mean            1.48438    0.15511   9.570  &lt; 2e-16 ***\naridity_x_p_mean  0.10484    0.07198   1.457    0.146    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5696 on 531 degrees of freedom\nMultiple R-squared:  0.7697,    Adjusted R-squared:  0.7684 \nF-statistic: 591.6 on 3 and 531 DF,  p-value: &lt; 2.2e-16\n\n\n\ntest_data &lt;-  bake(prep(rec), new_data = camels_test)\ntest_data$lm_pred &lt;- predict(lm_base, newdata = test_data)\n\n\nmetrics(test_data, truth = logQmean, estimate = lm_pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +\n  # Apply a gradient color scale\n  scale_color_gradient2(low = \"brown\", mid = \"orange\", high = \"darkgreen\") +\n  geom_point() +\n  geom_abline(linetype = 2) +\n  theme_linedraw() + \n  labs(title = \"Linear Model: Observed vs Predicted\",\n       x = \"Observed Log Mean Flow\",\n       y = \"Predicted Log Mean Flow\",\n       color = \"Aridity\")\n\n\n\n\n\n\n\n\n\n# Define model\nlm_model &lt;- linear_reg() %&gt;%\n  # define the engine\n  set_engine(\"lm\") %&gt;%\n  # define the mode\n  set_mode(\"regression\")\n\n# Instantiate a workflow ...\nlm_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(lm_model) %&gt;%\n  # Fit the model to the training data\n  fit(data = camels_train) \n\n# Extract the model coefficients from the workflow\nsummary(extract_fit_engine(lm_wf))$coefficients\n\n                   Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)      -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity          -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean            1.4843771 0.15511117   9.569762 4.022500e-20\naridity_x_p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\n# From the base implementation\nsummary(lm_base)$coefficients\n\n                 Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)    -1.7758557 0.16364755 -10.851710 6.463654e-25\naridity        -0.8839738 0.16144589  -5.475357 6.745512e-08\np_mean          1.4843771 0.15511117   9.569762 4.022500e-20\naridity:p_mean  0.1048449 0.07198145   1.456555 1.458304e-01\n\n\n\n#\nlm_data &lt;- augment(lm_wf, new_data = camels_test)\ndim(lm_data)\n\n[1] 135  61\n\nmetrics(lm_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.583\n2 rsq     standard       0.742\n3 mae     standard       0.390\n\n\n\nggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nlibrary(baguette)\n\nrf_model &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\nrf_wf &lt;- workflow() %&gt;%\n  # Add the recipe\n  add_recipe(rec) %&gt;%\n  # Add the model\n  add_model(rf_model) %&gt;%\n  # Fit the model\n  fit(data = camels_train) \n\nrf_data &lt;- augment(rf_wf, new_data = camels_test)\ndim(rf_data)\n\n[1] 135  60\n\nmetrics(rf_data, truth = logQmean, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.592\n2 rsq     standard       0.736\n3 mae     standard       0.367\n\n\n\nggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +\n  scale_color_viridis_c() +\n  geom_point() +\n  geom_abline() +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\nwf &lt;- workflow_set(list(rec), list(lm_model, rf_model)) %&gt;%\n  workflow_map('fit_resamples', resamples = camels_cv) \n\nautoplot(wf)\n\n\n\n\n\n\n\n\nDemo –^\n\n\nQuestion 2\n\nmap_1 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = aridity)) + \n  scale_color_gradient(low = \"lightblue\", high = \"orange\") +\n  coord_fixed() +\n  labs(title = \"Aridity across the U.S\",\n       x = \"Longitude\", y = \"Latitude\", color = \"Aridity (Priestley-Taylor formulation)\") +\n    ggthemes::theme_map() +\n   theme(\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\")\n\n\nmap_2 &lt;- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +\n  borders(\"state\", colour = \"gray50\") +\n  geom_point(aes(color = p_mean)) + \n  scale_color_gradient(low = \"pink\", high = \"lightblue\") +\n  coord_fixed() +\n  labs(title = \"Mean Daily Preciptiation Across the U.S\",\n       x = \"Longitude\", y = \"Latitude\", color = \"Mean Precipitation (mm/day)\") +\n    ggthemes::theme_map() +\n   theme(\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\")\n\n\nlibrary(patchwork)\nmap_1 + map_2\n\n\n\n\n\n\n\n\n\n\nQuestion 3\nDefine additional models\n\n# XGBoost\nxgb_model &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\n# Bagged MLP Neural Net\nmlp_model &lt;- bag_mlp() %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\nCreate workflows\n\n# XGBoost Workflow\nxgb_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(xgb_model) %&gt;%\n  fit(data = camels_train)\n\n# Bagged Neural Net Workflow\nmlp_wf &lt;- workflow() %&gt;%\n  add_recipe(rec) %&gt;%\n  add_model(mlp_model) %&gt;%\n  fit(data = camels_train)\n\nPredictions\n\n# Predict and add to test set\nlm_data &lt;- camels_test %&gt;%\n  mutate(.pred = predict(lm_wf, .)$.pred)\n\nrf_data &lt;- camels_test %&gt;%\n  mutate(.pred = predict(rf_wf, .)$.pred)\n\nxgb_data &lt;- camels_test %&gt;%\n  mutate(.pred = predict(xgb_wf, .)$.pred)\n\nmlp_data &lt;- camels_test %&gt;%\n  mutate(.pred = predict(mlp_wf, .)$.pred)\n\nEvaluate metrics\n\nmodel_metrics &lt;- bind_rows(\n  metrics(lm_data, truth = logQmean, estimate = .pred) %&gt;% mutate(model = \"Linear\"),\n  metrics(rf_data, truth = logQmean, estimate = .pred) %&gt;% mutate(model = \"Random Forest\"),\n  metrics(xgb_data, truth = logQmean, estimate = .pred) %&gt;% mutate(model = \"XGBoost\"),\n  metrics(mlp_data, truth = logQmean, estimate = .pred) %&gt;% mutate(model = \"Bagged MLP\")\n) %&gt;%\n  select(model, everything())\nprint(model_metrics)\n\n# A tibble: 12 × 4\n   model         .metric .estimator .estimate\n   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n 1 Linear        rmse    standard       0.583\n 2 Linear        rsq     standard       0.742\n 3 Linear        mae     standard       0.390\n 4 Random Forest rmse    standard       0.592\n 5 Random Forest rsq     standard       0.736\n 6 Random Forest mae     standard       0.367\n 7 XGBoost       rmse    standard       0.631\n 8 XGBoost       rsq     standard       0.702\n 9 XGBoost       mae     standard       0.397\n10 Bagged MLP    rmse    standard       0.559\n11 Bagged MLP    rsq     standard       0.761\n12 Bagged MLP    mae     standard       0.348\n\n\nVisualize XGB\n\nxgb_preds &lt;- camels_test %&gt;%\n  mutate(.pred = predict(xgb_wf, .)$.pred)\n\nggplot(xgb_preds, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point(alpha = 0.6) +\n  geom_abline(linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"XGBoost: Observed vs Predicted\",\n    x = \"Observed logQmean\",\n    y = \"Predicted logQmean\"\n  )\n\n\n\n\n\n\n\n\nVisualize MLP\n\nmlp_preds &lt;- camels_test %&gt;%\n  mutate(.pred = predict(mlp_wf, .)$.pred)\n\nggplot(mlp_preds, aes(x = logQmean, y = .pred, color = aridity)) +\n  scale_color_viridis_c() +\n  geom_point(alpha = 0.6) +\n  geom_abline(linetype = \"dashed\") +\n  theme_minimal() +\n  labs(\n    title = \"Bagged MLP: Observed vs Predicted\",\n    x = \"Observed logQmean\",\n    y = \"Predicted logQmean\"\n  )\n\n\n\n\n\n\n\n\nFor modeling this data, I would chose the Bagged MLP model as it preforms the best. It has the lowest RMSE and MAE, which indicates better accuracy. It also has the highest R^2 which indicated better correlations.\n\n\nQuestion 4\n\n# Set seed for reproducibility\nset.seed(1102)\n\n#removing NAs \ncamels |&gt; \n  select(slope_mean, p_mean, logQmean) |&gt; \n  drop_na() |&gt; \n  cor()\n\n           slope_mean    p_mean  logQmean\nslope_mean  1.0000000 0.2602688 0.3687933\np_mean      0.2602688 1.0000000 0.8053056\nlogQmean    0.3687933 0.8053056 1.0000000\n\n# Initial train/test split\nsplit &lt;- initial_split(camels, prop = 0.75)\ncamels_train &lt;- training(split)\ncamels_test  &lt;- testing(split)\n\n# Create 10-fold cross-validation\ncv_folds &lt;- vfold_cv(camels_train, v = 10)\n\n# Defining my recipe\nrec2 &lt;- recipe(logQmean ~ p_mean + slope_mean  , data = camels_train) %&gt;%\n  step_log(all_predictors())%&gt;%\n  step_interact(terms = ~ p_mean:slope_mean) %&gt;%\n  step_naomit(all_predictors(), all_outcomes())               \n\nFor this formula I chose slope_mean and p_mean. Slope_mean is the mean slope of the catchment. I assumed this would impact discharge because the water is more likely to run off and down the catchment due to gravity, and I suspect that all other variables held constant, and area with a greater slope would have greater daily discharge. I also chose p_mean which is mean daily precipitation, which would influence discharge because more water in the area means more area in the river/stream. I chose to add these together because greater values of each variable would compound into greater discharge.\n\n#Bake Data\nbaked_data2 &lt;- prep(rec2, camels_train) %&gt;%\n  bake(new_data = NULL)\n\n#linear model\nlm_base2 &lt;- lm(logQmean ~ p_mean * slope_mean, data = baked_data2)\nsummary(lm_base2)\n\n\nCall:\nlm(formula = logQmean ~ p_mean * slope_mean, data = baked_data2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.59234 -0.26155  0.02523  0.25449  1.65766 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -4.77993    0.17535 -27.260   &lt;2e-16 ***\np_mean             3.67249    0.15618  23.515   &lt;2e-16 ***\nslope_mean         0.62593    0.04691  13.344   &lt;2e-16 ***\np_mean:slope_mean -0.37395    0.04010  -9.326   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4877 on 498 degrees of freedom\nMultiple R-squared:  0.8372,    Adjusted R-squared:  0.8362 \nF-statistic: 853.6 on 3 and 498 DF,  p-value: &lt; 2.2e-16\n\n\nI could not find variables with an R^2 &gt;0.9, but this once is high and about the closest I found\nDefine Models\n\nxgb_model2 &lt;- boost_tree() %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\nrf_model2 &lt;- rand_forest() %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\nlm_model2 &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\")%&gt;%\n  set_mode(\"regression\")\n\nCreating workflow\n\n# Linear regression workflow\n\nlm_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(lm_model2)\n\n# Random forest workflow\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2)\n\n# XGBoost workflow\nxgb_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(xgb_model2)\n\nFit to resamples\n\n# Fit linear model\nlm_res &lt;- fit_resamples(\n  lm_workflow,\n  resamples = cv_folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n# Fit random forest\nrf_res &lt;- fit_resamples(\n  rf_workflow,\n  resamples = cv_folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\n# Fit XGBoost\nxgb_res &lt;- fit_resamples(\n  xgb_workflow,\n  resamples = cv_folds,\n  control = control_resamples(save_pred = TRUE)\n)\n\nCreate workflow set\n\n# Create a workflow set\nmodel_set &lt;- workflow_set(\n  preproc = list(rec2 = rec2),\n  models = list(\n    linear_reg = lm_model2,\n    random_forest = rf_model2,\n    xgboost = xgb_model2\n  )\n)\n\n# Tune all models in the workflow set\nmodel_set_res &lt;- model_set %&gt;%\n  workflow_map(\"tune_grid\", resamples = cv_folds)\n\nRank results\n\n# Rank based on RMSE\nrank_results(model_set_res, rank_metric = \"rmse\")\n\n# A tibble: 6 × 9\n  wflow_id          .config .metric  mean std_err     n preprocessor model  rank\n  &lt;chr&gt;             &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt; &lt;int&gt;\n1 rec2_random_fore… Prepro… rmse    0.438  0.0239    10 recipe       rand…     1\n2 rec2_random_fore… Prepro… rsq     0.875  0.0113    10 recipe       rand…     1\n3 rec2_xgboost      Prepro… rmse    0.470  0.0237    10 recipe       boos…     2\n4 rec2_xgboost      Prepro… rsq     0.861  0.0117    10 recipe       boos…     2\n5 rec2_linear_reg   Prepro… rmse    0.485  0.0251    10 recipe       line…     3\n6 rec2_linear_reg   Prepro… rsq     0.842  0.0116    10 recipe       line…     3\n\n\nPlot results\n\nautoplot(model_set_res)\n\n\n\n\n\n\n\n\nThe model that I think is best is the Random Forest, as it has the lowest RMSE, indicating best prediction accuracy on average. it also has the highest R^2 and a low standard error, which indicates that this model explains the most variance in streamflow, nad is also relatively stable across the 10 reseamples.\nExtract and evaluate\n\nfinal_rf_workflow &lt;- workflow() %&gt;%\n  add_recipe(rec2) %&gt;%\n  add_model(rf_model2)\n\nfinal_rf_fit &lt;- final_rf_workflow %&gt;%\n  fit(data = camels_train)\n\nrf_predictions &lt;- augment(final_rf_fit, new_data = camels_test)\n\nggplot(rf_predictions, aes(x = .pred, y = logQmean)) + \n  geom_point(aes(color = slope_mean ), alpha = 0.7) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n  labs(\n    title = \"Observed vs. Predicted Mean Streamflow\",\n    x = \"Predicted Streamflow (logQmean)\",\n    y = \"Observed Streamflow (logQmean)\",\n    color = \"Mean Slope (m/km)\"\n  ) +\n  scale_color_viridis_c() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nIn these results I see that where the stream flow is low, it is harder to predict based on my defined variables. This makes sense because I know that when streams or areas are dry, any precipitation can cause them to become “flashy”. Where the stream flow is positive, the observed and predicted stream flow are much closer together and the fit seems good. I can also see that there is a good trend in slope and flow, where more slope creates more observed streamlow, as I predicted."
  }
]