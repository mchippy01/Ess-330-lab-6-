---
title: " ESS 330 lab 6"
author: "Chippy Marx"
date: "2025-04-01"
format: html
execute:
  echo: true
---

```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(ggplot2)
```

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')
 

```

```{r}
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')
walk2(remote_files, local_files, download.file, quiet = TRUE)
# Read and merge data
camels <- map(local_files, read_delim, show_col_types = FALSE) 
```

```{r}
camels <- power_full_join(camels ,by = 'gauge_id')
```

```{r}
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

zero_q_freq represents frequency of days with Q = 0 mm/day (%), where Q=Â flow.

```{r}
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

```{r}
# Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
  # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
  # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  # Apply the viridis color scale
  scale_color_viridis_c() +
  # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

```{r}
set.seed(123)
# Bad form to perform simple transformations on the outcome variable within a 
# recipe. So, we'll do it here.
camels <- camels |> 
  mutate(logQmean = log(q_mean))

# Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

```{r}
# Create a recipe to preprocess the data
rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
  # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) |> 
  # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes())
# Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

# Interaction with lm
#  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

```{r}
# Sanity Interaction term from recipe ... these should be equal!!
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

```{r}
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)

```

```{r}
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

```{r}
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients
```

```{r}
# From the base implementation
summary(lm_base)$coefficients
```

```{r}
#
lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)

metrics(lm_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

```{r}
library(baguette)

rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 

rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)

metrics(rf_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()

```

```{r}
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)
```

```{r}
map_1 <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) + 
  scale_color_gradient(low = "lightblue", high = "orange") +
  coord_fixed() +
  labs(title = "Aridity across the U.S",
       x = "Longitude", y = "Latitude", color = "Aridity (Priestley-Taylor formulation)") +
    ggthemes::theme_map() +
   theme(
    legend.position = "bottom",
    legend.direction = "horizontal")


```

```{r}
map_2 <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean)) + 
  scale_color_gradient(low = "pink", high = "lightblue") +
  coord_fixed() +
  labs(title = "Mean Daily Preciptiation Across the U.S",
       x = "Longitude", y = "Latitude", color = "Mean Precipitation (mm/day)") +
    ggthemes::theme_map() +
   theme(
    legend.position = "bottom",
    legend.direction = "horizontal")
```

```{r}
library(patchwork)
map_1 + map_2
```

Question 3

define additonal models

```{r}

# XGBoost
xgb_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")

# Bagged MLP Neural Net
mlp_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

```

Create workflows

```{r}

# XGBoost Workflow
xgb_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(xgb_model) %>%
  fit(data = camels_train)

# Bagged Neural Net Workflow
mlp_wf <- workflow() %>%
  add_recipe(rec) %>%
  add_model(mlp_model) %>%
  fit(data = camels_train)
```

Predictions

```{r}
# Predict and add to test set
lm_data <- camels_test %>%
  mutate(.pred = predict(lm_wf, .)$.pred)

rf_data <- camels_test %>%
  mutate(.pred = predict(rf_wf, .)$.pred)

xgb_data <- camels_test %>%
  mutate(.pred = predict(xgb_wf, .)$.pred)

mlp_data <- camels_test %>%
  mutate(.pred = predict(mlp_wf, .)$.pred)

```

```{r}
model_metrics <- bind_rows(
  metrics(lm_data, truth = logQmean, estimate = .pred) %>% mutate(model = "Linear"),
  metrics(rf_data, truth = logQmean, estimate = .pred) %>% mutate(model = "Random Forest"),
  metrics(xgb_data, truth = logQmean, estimate = .pred) %>% mutate(model = "XGBoost"),
  metrics(mlp_data, truth = logQmean, estimate = .pred) %>% mutate(model = "Bagged MLP")
) %>%
  select(model, everything())
print(model_metrics)

```

```{r}
xgb_preds <- camels_test %>%
  mutate(.pred = predict(xgb_wf, .)$.pred)

ggplot(xgb_preds, aes(x = logQmean, y = .pred, color = aridity)) +
  scale_color_viridis_c() +
  geom_point(alpha = 0.6) +
  geom_abline(linetype = "dashed") +
  theme_minimal() +
  labs(
    title = "XGBoost: Observed vs Predicted",
    x = "Observed logQmean",
    y = "Predicted logQmean"
  )

```

```{r}
mlp_preds <- camels_test %>%
  mutate(.pred = predict(mlp_wf, .)$.pred)

ggplot(mlp_preds, aes(x = logQmean, y = .pred, color = aridity)) +
  scale_color_viridis_c() +
  geom_point(alpha = 0.6) +
  geom_abline(linetype = "dashed") +
  theme_minimal() +
  labs(
    title = "Bagged MLP: Observed vs Predicted",
    x = "Observed logQmean",
    y = "Predicted logQmean"
  )

```

For modeling this data, I would chose the Bagged MLp model as it preforms the best. It has the lowest RMSE and MAE, which indicates better accuracy. It also has the highest R\^2 which indicated better correlations.

Question 4

```{r}
# Set seed for reproducibility
set.seed(1102)

camels |> 
  select(slope_mean, p_mean, logQmean) |> 
  drop_na() |> 
  cor()

# Initial train/test split (75% train, 25% test)
split <- initial_split(camels, prop = 0.75)
camels_train <- training(split)
camels_test  <- testing(split)

# Create 10-fold cross-validation
cv_folds <- vfold_cv(camels_train, v = 10)

# Define your recipe
rec2 <- recipe(logQmean ~ p_mean + slope_mean  , data = camels_train) %>%
  step_log(all_predictors())%>%
  step_interact(terms = ~ p_mean:slope_mean) %>%
  step_naomit(all_predictors(), all_outcomes())               


```

For this formula I chose slope_mean and p_mean. Slope_mean is the mean slope of the catchment. I assumed this would impact discharge because the water is more likely to run off and down the catchment due to gravity, and I suspect that all other variables held constant, and area with a greater slope would have greater daily discharge. I also chose p_mean which is mean daily precipitation, which would influence discharge because more water in the area means more area in the river/stream. I chose to add these together because greater values of each variable would compound into greater discharge.

```{r}
baked_data2 <- prep(rec2, camels_train) %>%
  bake(new_data = NULL)


lm_base2 <- lm(logQmean ~ p_mean * slope_mean, data = baked_data2)
summary(lm_base2)

```

```{r}
xgb_model2 <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("regression")

rf_model2 <- rand_forest() %>%
  set_engine("ranger") %>%
  set_mode("regression")

lm_model2 <- linear_reg() %>%
  set_engine("lm")%>%
  set_mode("regression")

```

Creating workflow

```{r}
# Linear regression workflow

lm_workflow <- workflow() %>%
  add_recipe(rec2) %>%
  add_model(lm_model2)

# Random forest workflow
rf_workflow <- workflow() %>%
  add_recipe(rec2) %>%
  add_model(rf_model2)

# XGBoost workflow
xgb_workflow <- workflow() %>%
  add_recipe(rec2) %>%
  add_model(xgb_model2)

```

Fit to resamples

```{r}
# Fit linear model
lm_res <- fit_resamples(
  lm_workflow,
  resamples = cv_folds,
  control = control_resamples(save_pred = TRUE)
)

# Fit random forest
rf_res <- fit_resamples(
  rf_workflow,
  resamples = cv_folds,
  control = control_resamples(save_pred = TRUE)
)

# Fit XGBoost
xgb_res <- fit_resamples(
  xgb_workflow,
  resamples = cv_folds,
  control = control_resamples(save_pred = TRUE)
)

```

Rank Results

```{r}
# Create a workflow set
model_set <- workflow_set(
  preproc = list(rec2 = rec2),
  models = list(
    linear_reg = lm_model2,
    random_forest = rf_model2,
    xgboost = xgb_model2
  )
)

# Tune all models in the workflow set
model_set_res <- model_set %>%
  workflow_map("tune_grid", resamples = cv_folds)
```

```{r}
# Rank based on RMSE
rank_results(model_set_res, rank_metric = "rsq")


```

```{r}
autoplot(model_set_res)
```

The model that I think is best is the Random Forest, as it has the lowest RMSE, indicatinf best prediction accuracy on average. it also has the highest R\^2 and a low standard error, which indicates that this model explains the most variance in streamflow, nad is also relatively stable across the 10 reseamples.

**Exact and evaluate**

```{r}
final_rf_workflow <- workflow() %>%
  add_recipe(rec2) %>%
  add_model(rf_model2)

final_rf_fit <- final_rf_workflow %>%
  fit(data = camels)

rf_predictions <- augment(final_rf_fit, new_data = camels_test)

ggplot(rf_predictions, aes(x = .pred, y = logQmean)) + 
  geom_point(aes(color = .pred), alpha = 0.7) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "Observed vs. Predicted Mean Streamflow",
    x = "Predicted Streamflow",
    y = "Observed Streamflow",
    color = "Prediction"
  ) +
  scale_color_viridis_c() +
  theme_minimal()

```
